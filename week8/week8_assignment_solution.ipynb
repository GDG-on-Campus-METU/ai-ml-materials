{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPPYJIcKsfqsJRAc5uPIJQE"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["\n","\n","---\n","\n","\n","# 00. About Assignment\n","\n","\n","---\n","\n"],"metadata":{"id":"QKDnB-MZaDZr"}},{"cell_type":"markdown","source":["**There are 1 question in this assignment**\n","\n","\n","**To complete this assignment:**\n","\n","1.   Replace **all** `#TODO` comments with your answers.\n","2.   Run **all** code blocks under \"01. Assignment\" section.\n","3.   Run the code block under \"02. Complete the Assignment\" section.\n","4.   Confirm that you completed this assignment without cheating by typing `\"I confirm\"`\n","4.   A csv file named `w8_submission.csv ` and a h5 file named `model.h5` will appear on files (you can reach files on the bar on the left) after you run the block.\n","5. Download `w8_submission.csv`.\n","5.   Download `model.h5`.\n","5.   Send .csv and .h5 files to your instructors via Google Classroom."],"metadata":{"id":"kqldi1S6aaBw"}},{"cell_type":"markdown","source":["\n","\n","---\n","\n","\n","# 01. Assignment\n","\n","\n","---\n","\n"],"metadata":{"id":"u1RPVvL8aj6F"}},{"cell_type":"markdown","source":["## Q0 - Personal Info"],"metadata":{"id":"XDmPK7bobic_"}},{"cell_type":"code","source":["from datetime import datetime\n","\n","now = datetime.now()\n","datetimenow = now.strftime(\"%d/%m/%Y %H:%M:%S\")\n","name = input(\"Enter your full name:  \")"],"metadata":{"id":"qETsfYsEb1nQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1728687233663,"user_tz":-180,"elapsed":15746,"user":{"displayName":"Efe Kaan Güler","userId":"05746327085556081300"}},"outputId":"73b35854-e273-4b10-a36c-83ce282a99a3"},"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Enter your full name:  Efe Kaan Güler\n"]}]},{"cell_type":"markdown","source":["## Q1 - Creating training and evaluating a RNN"],"metadata":{"id":"oQJ6_2EYboaH"}},{"cell_type":"markdown","source":["1.   Import libraries that you will use.\n","2.   Check https://www.tensorflow.org/datasets/catalog/imdb_reviews for documentation of the `imdb_reviews` dataset\n","2.   Load `imdb_reviews` dataset using `tensorflow_datasets` library.\n","4.   Preprocess the dataset. (Test data must be assigned to the variable `test_padded`)\n","6.   Create a RNN model and assign it to variable `model`. (do not use pre-trained models or embeddings)\n","7.   Compile the model. (Set `metrics = [\"accuracy\"]`)\n","8.   Train the model.\n","9.   Evaluate the model\n","11.   If you reached over %80 test accuracy, run the grading block\n","11.   To pass this assignment, the test accuracy must be over %80.\n","\n","\n","\n","\n","\n"],"metadata":{"id":"dorUk7nUcuHp"}},{"cell_type":"code","source":["# Import libraries\n","import numpy as np\n","import tensorflow as tf\n","import tensorflow_datasets as tfds"],"metadata":{"id":"x-wx8Zzse-Mq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data, ds_info = tfds.load(\n","    \"imdb_reviews\",\n","    split=[\"train\", \"test\"],\n","    with_info=True,\n","    shuffle_files=True,\n","    as_supervised=True,\n",")\n","train_data, test_data = data\n","ds_info.features"],"metadata":{"id":"tcAsSLnWetic","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1728687237704,"user_tz":-180,"elapsed":1005,"user":{"displayName":"Efe Kaan Güler","userId":"05746327085556081300"}},"outputId":"31f8bad4-dac4-432e-cb26-2ec430ebac3a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["FeaturesDict({\n","    'label': ClassLabel(shape=(), dtype=int64, num_classes=2),\n","    'text': Text(shape=(), dtype=string),\n","})"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["class_names = ds_info.features[\"label\"].names\n","class_names"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aCnBlKNKnEU0","executionInfo":{"status":"ok","timestamp":1728687237704,"user_tz":-180,"elapsed":6,"user":{"displayName":"Efe Kaan Güler","userId":"05746327085556081300"}},"outputId":"835c8002-f00b-4ed6-c748-2c05c2afd403"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['neg', 'pos']"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["sample = train_data.take(1)\n","for text, label in sample:\n","    print(text.numpy())\n","    print(label.numpy())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IkWfANb8nb0V","executionInfo":{"status":"ok","timestamp":1728687237704,"user_tz":-180,"elapsed":4,"user":{"displayName":"Efe Kaan Güler","userId":"05746327085556081300"}},"outputId":"719ab6d0-56a9-428c-c02e-3d9eeae74a6d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["b\"This was an absolutely terrible movie. Don't be lured in by Christopher Walken or Michael Ironside. Both are great actors, but this must simply be their worst role in history. Even their great acting could not redeem this movie's ridiculous storyline. This movie is an early nineties US propaganda piece. The most pathetic scenes were those when the Columbian rebels were making their cases for revolutions. Maria Conchita Alonso appeared phony, and her pseudo-love affair with Walken was nothing but a pathetic emotional plug in a movie that was devoid of any real meaning. I am disappointed that there are movies like this, ruining actor's like Christopher Walken's good name. I could barely sit through it.\"\n","0\n"]}]},{"source":["from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","\n","train_texts = [x.numpy().decode('utf-8') for x, y in train_data]\n","test_texts = [x.numpy().decode('utf-8') for x, y in test_data]\n","\n","tokenizer = Tokenizer(num_words=1000, oov_token=\"<OOV>\")\n","tokenizer.fit_on_texts(train_texts)\n","\n","vocab_size = len(tokenizer.word_index) + 1\n","\n","train_sequences = tokenizer.texts_to_sequences(train_texts)\n","train_padded = pad_sequences(train_sequences, padding='post', maxlen=100)\n","\n","test_sequences = tokenizer.texts_to_sequences(test_texts)\n","test_padded = pad_sequences(test_sequences, padding='post', maxlen=100)\n","\n","print(f\"Padded training sequences have shape: {train_padded.shape}\\n\")\n","print(f\"Padded validation sequences have shape: {test_padded.shape}\")"],"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5IQ-JfpuqVUi","executionInfo":{"status":"ok","timestamp":1728687278669,"user_tz":-180,"elapsed":40968,"user":{"displayName":"Efe Kaan Güler","userId":"05746327085556081300"}},"outputId":"546d5648-ad6a-4a3f-84e3-f07ecaadc25f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Padded training sequences have shape: (25000, 100)\n","\n","Padded validation sequences have shape: (25000, 100)\n"]}]},{"cell_type":"code","source":["train_labels = np.array([y.numpy() for x, y in train_data])\n","test_labels = np.array([y.numpy() for x, y in test_data])\n","\n","print(f\"Padded training sequences have shape: {train_labels.shape}\\n\")\n","print(f\"Padded validation sequences have shape: {test_labels.shape}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dxadx5wrsv0E","executionInfo":{"status":"ok","timestamp":1728687296589,"user_tz":-180,"elapsed":17923,"user":{"displayName":"Efe Kaan Güler","userId":"05746327085556081300"}},"outputId":"e27f718e-3f48-4e7e-b918-664cd7c2cfff"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Padded training sequences have shape: (25000,)\n","\n","Padded validation sequences have shape: (25000,)\n"]}]},{"cell_type":"code","source":["model = tf.keras.Sequential([\n","    tf.keras.Input(shape=(100,)),\n","    tf.keras.layers.Embedding(1000, 32),\n","    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(20, return_sequences=True)),\n","    tf.keras.layers.Dropout(0.2),\n","    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(20)),\n","    tf.keras.layers.Dropout(0.2),\n","    tf.keras.layers.Dense(32, activation=\"relu\"),\n","    tf.keras.layers.Dropout(0.2),\n","    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n","    ])\n","\n","# A simplier DNN model will perform better on this task, however our goal is to learn how to use RNN's."],"metadata":{"id":"iDa83qevwx9x"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.compile(loss=tf.keras.losses.binary_crossentropy,\n","              optimizer=tf.keras.optimizers.Adam(),\n","              metrics=['accuracy'])"],"metadata":{"id":"E6hLMZk0sIkL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.fit(\n","    train_padded,\n","    train_labels,\n","    epochs=5,\n","    validation_data=(test_padded, test_labels)\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vNwdolJAsiIS","executionInfo":{"status":"ok","timestamp":1728687484397,"user_tz":-180,"elapsed":187811,"user":{"displayName":"Efe Kaan Güler","userId":"05746327085556081300"}},"outputId":"ac99b0e0-ce8c-4ef4-b36e-4c95ba2aa774"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 27ms/step - accuracy: 0.6603 - loss: 0.5797 - val_accuracy: 0.8014 - val_loss: 0.4183\n","Epoch 2/5\n","\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 32ms/step - accuracy: 0.8373 - loss: 0.3761 - val_accuracy: 0.8282 - val_loss: 0.3763\n","Epoch 3/5\n","\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 26ms/step - accuracy: 0.8522 - loss: 0.3432 - val_accuracy: 0.8402 - val_loss: 0.3536\n","Epoch 4/5\n","\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 33ms/step - accuracy: 0.8625 - loss: 0.3199 - val_accuracy: 0.8382 - val_loss: 0.3604\n","Epoch 5/5\n","\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 28ms/step - accuracy: 0.8739 - loss: 0.2969 - val_accuracy: 0.8392 - val_loss: 0.3606\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.history.History at 0x7b2b784d1060>"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["# THIS BLOCK IS FOR GRADING\n","# DO NOT MODIFY THIS BLOCK\n","\n","eval = model.evaluate(test_padded, test_labels)\n","q1_answer = [eval]\n","print(q1_answer)"],"metadata":{"id":"5IHD11RoevjL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1728687557221,"user_tz":-180,"elapsed":10775,"user":{"displayName":"Efe Kaan Güler","userId":"05746327085556081300"}},"outputId":"e5ed9ea2-8b87-4e05-9d8e-ecbcb7bca9b3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.8384 - loss: 0.3636\n","[[0.3606431782245636, 0.8392000198364258]]\n"]}]},{"cell_type":"markdown","source":["\n","\n","---\n","\n","\n","# 02. Complete the Assignment\n","\n","\n","---\n","\n"],"metadata":{"id":"PHvFF7tYao-K"}},{"cell_type":"code","source":["import pandas as pd\n","\n","answers = [q1_answer]\n","\n","print(\"I confirm that I did all the homework in this assignment by myself.\\nI understand that if I am found to have cheated, I will forfeit my right to receive a certificate.\")\n","confirmation = input(\"If you confirm the statement given above, type 'I confirm' to submit: \")\n","data = {\n","    \"name\": [\"name\", \"datetime\", \"confirmation\", \"answers\"],\n","    \"data\": [name, datetimenow, confirmation, answers]\n","}\n","answers_df = pd.DataFrame(data)\n","answers_df.set_index(\"name\", inplace=True)\n","answers_df.to_csv(\"w8_submission.csv\", index=True)\n","model.save(\"model.h5\")"],"metadata":{"id":"9olQlqVTaL59","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1728687578359,"user_tz":-180,"elapsed":6563,"user":{"displayName":"Efe Kaan Güler","userId":"05746327085556081300"}},"outputId":"724fb6c1-b0e0-4283-9aab-f53806301b0b"},"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["I confirm that I did all the homework in this assignment by myself.\n","I understand that if I am found to have cheated, I will forfeit my right to receive a certificate.\n","If you confirm the statement given above, type 'I confirm' to submit: I confirm\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]}]}]}